# Puntuguese with Gen AI #

## How to run the experiments ##

The script used to send requests to classification is `./classificate_phrases.py`.

Example

```
python3 ./classificate_phrases.py ./data/testWithout10shot.csv ./prompts/phrases_classification.txt ./config1.db
```

### Configurations tested ###

All the configurations used a guideline generated by the model through the process:
1. Select 100 random rows with label `Trocadilho` from `./data/classification_corpus_unique_pairs.csv` and its 100 correspondent `Não trocadilho` pairs;
2. A prompt with those rows followed by a message asking LLM to generate a guideline for annotation. The prompt is located at `./prompts/guideline_generation.txt`;
3. The prompt generated is located at `./prompts/guideline_generated.txt`.

#### First configuration - Zero shot, one phrase ####
* Prompt used for classification was `./prompts/phrases_classification.txt`
* Data used for classification was `./data/testWithout10shot.csv`
* Results in `./results/config1.1.db`

#### Second configuration - 10 shot, one phrase ####
* Prompt used for classification was `./prompts/phrases_classification10shot.txt`
* Data used for classification was `./data/testWithout10shot.csv`
* Results in `./results/config2.1.db`

#### Third configuration - 10 shot with chain of thought, one phrase ####

* Prompt used for classification was `./prompts/phrases_classification10shotPunSigns.txt`
* Data used for classification was `./data/testWithout10shot.csv`
* Results in `./results/config3.1.db`

## TODO

- [x] Rodar config 1.1
- [x] Rodar config 1.2
- [x] Rodar config 1.3
- [ ] Rodar config 2.1
- [ ] Rodar config 2.2
- [ ] Rodar config 2.3
- [ ] Corrigir as linhas nos results com PARSE_ERROR
- [ ] Criar o script de métricas. Utilizar matriz de confusão, precision, recall, F1 e F2
- [ ] SE SOBRAR TEMPO rodar todas as configs usando o modelo do gemini
